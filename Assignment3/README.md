# Assignment 3

All questions/subquestions have been attempted. In case of any discrepancies please contact either of the group members.<br>
We have tried our best to adhere to all the naming conventions as described in the problem statement.

## A quick walk through the files

Following is a list of the files and possible options in them :

* **src.c(code)** <br>
	Main communication script:<br>
	The code can be understood to be divided into four major components:
	- Read Data: We first read the data from the given file from the process ranked 0.
	- Broadcast Metadata: The number of rows and columns are broadcasted to each process.
	- Distribute Data(Scatterv): This relevant parts of this read data are then communicated to all the processes.
	- Calculate Yearwise Minimum: Each process then calculates the yearwise minimum for the row that was communicated to it.
	- Reduce/Gather Data: The minima calculated are now communicated back to the root process(We use a Reduce call for it).
	- Compute Global Minimum: We compute the global minimum from the yearwise minima gathered from all processes
	- Print Data: The data for yearwise minima, global minimum and execution time is then dumped. 

```sh
	mpirun -np P -ppn PPN -f hostfile ./code tdata.csv   
            #P is the number of processes, PPN is the processes per node.
```

* **Makefile**

```sh
	make        # Builds the executable for src.c named code
	make clean  # Removes the executables binaries created in the make process. 
```

*	**script.py**<br>
	The helper script provided to generate the hostfile.

*	**plot.py**<br>
	The helper plotting script provided: Uses `data.csv` file to generate the required plots.

*	**run.sh**<br>
	The Job script: Triggers various components of the assignment(`Makefile`, `script.py`, `src.c`, `plot.py`). <br>

```sh
	bash run.sh
```

*	**output.txt**<br>
	Holds the data in the required format for the latest execution.(Overwritten by each configuration)

*	**data.csv**<br>
	A data file generated by `run.sh` as the time data dump corresponding to the configurations used for plotting purposes.

*	**plot.jpg**<br>
	A Box plot generated by `run.sh` representing data points corresponding to each various configurations.	

## Running the code


```sh
	cd Assignment3
	bash run.sh
```

Files created in this process include `code`(executable for src.c), `hostfile`, `output.txt`, `data.csv` & `plot.jpg` .

## Data Distribution Strategy

We distribute the data from the given file in a row major manner. Each row(corresponding to a location or station) is scheduled to be sent to a specific process in the current running configuration. The root process first broadcasts the number of rows and columns to each process. The vectors for the rows to be sent to a process are created at the root process and then are sent ahead using MPI_Scatterv.

The computed Local minima at each process level are then communicated back to the root process by a MPI_Reduce which reduces a vector of the yearwise data to get the yearwise minimum at rank=0.  

Earlier we considered distributing data in a column major manner. However, later realized that this sort of a technique could end up distributing the data unequally leaving a lot of computation in the nodes towards the end of the round-robin, when the number of columns were not an integral multiple of the number of processes being used. In row major manner as well, a few processes may get an additional row but the number of rows (430469 in the current file) is much higher than the number of columns (41). The maximum difference in the number of data points on each process is atmost equal to the number of columns in row major distribution whereas it is equal to the number of rows in column major distribution. Hence, the load imbalance will be more severe in column major distribution. Even when the files are changed we will expect the number of stations (rows) to be much higher than the number of years (columns).
Thus, we then changed to the approach earlier mentioned (row major) as it ensured that the computational work was always fairly distributed, putting no undue pressure on a few nodes.

## Observations

Any Scaling Up is not evident from the Box plot. We observe that the configuration (P=1,PPN=1) performs the best with a execution time in order of 0.3 seconds. Considering the practically no time here is spent in communication, we may deduce that the computation is of the same order. The rest of the configurations showcase an execution time of ~5 seconds which can be majorly attribute to the time spent in communication between these processes.

The conclusion being that with computation size as needed in the file provided, any scaling up if possible is outshadowed by the communication overheads. When the computation forms a larger component of the total time that is elapsed, we may expect a visible scaling in some of the given configurations

### Box Plots

![Comparison of Scaling Up](plot.jpg)


